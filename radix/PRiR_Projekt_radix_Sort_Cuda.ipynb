{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YFqZr2GONXLU",
        "outputId": "d07177e6-3d1d-4a6b-8059-b64437752e96"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tue Dec  2 18:10:07 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   47C    P8             10W /   70W |       0MiB /  15360MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from numba import cuda, int32\n",
        "import time\n",
        "\n",
        "# Rozmiar bloku (liczba wątków na blok)\n",
        "TPB = 32\n",
        "\n",
        "@cuda.jit\n",
        "def count_kernel(arr, histogram, exp, n):\n",
        "    s_counts = cuda.shared.array((10, TPB), dtype=int32)\n",
        "\n",
        "    tid = cuda.threadIdx.x\n",
        "    gid = cuda.grid(1)\n",
        "    bid = cuda.blockIdx.x\n",
        "\n",
        "    if tid < 10:\n",
        "        for i in range(TPB):\n",
        "            s_counts[tid, i] = 0\n",
        "    cuda.syncthreads()\n",
        "\n",
        "    digit = -1\n",
        "    if gid < n:\n",
        "        val = arr[gid]\n",
        "        digit = (val // exp) % 10\n",
        "        s_counts[digit, tid] = 1\n",
        "\n",
        "    cuda.syncthreads()\n",
        "\n",
        "    if tid < 10:\n",
        "        count = 0\n",
        "        for i in range(TPB):\n",
        "            count += s_counts[tid, i]\n",
        "        histogram[bid, tid] = count\n",
        "\n",
        "@cuda.jit\n",
        "def scatter_kernel(arr, out, global_offsets, exp, n):\n",
        "\n",
        "    s_data = cuda.shared.array(TPB, dtype=int32)\n",
        "    s_ranks = cuda.shared.array(TPB, dtype=int32)\n",
        "\n",
        "    tid = cuda.threadIdx.x\n",
        "    gid = cuda.grid(1)\n",
        "    bid = cuda.blockIdx.x\n",
        "\n",
        "    val = 0\n",
        "    digit = -1\n",
        "    if gid < n:\n",
        "        val = arr[gid]\n",
        "        s_data[tid] = val\n",
        "        digit = (val // exp) % 10\n",
        "    else:\n",
        "        s_data[tid] = -1\n",
        "        digit = 10\n",
        "\n",
        "    cuda.syncthreads()\n",
        "\n",
        "    if tid == 0:\n",
        "        temp_counts = cuda.local.array(11, dtype=int32)\n",
        "        for k in range(11):\n",
        "            temp_counts[k] = 0\n",
        "\n",
        "        for i in range(TPB):\n",
        "            d = -1\n",
        "            if s_data[i] != -1:\n",
        "                d = (s_data[i] // exp) % 10\n",
        "            else:\n",
        "                d = 10\n",
        "\n",
        "            s_ranks[i] = temp_counts[d]\n",
        "            temp_counts[d] += 1\n",
        "\n",
        "    cuda.syncthreads()\n",
        "\n",
        "    if gid < n:\n",
        "        final_pos = global_offsets[digit, bid] + s_ranks[tid]\n",
        "        out[final_pos] = val\n",
        "\n",
        "def radix_sort_cuda_stable(arr):\n",
        "    n = arr.size\n",
        "    arr = arr.astype(np.int32)\n",
        "    out = np.zeros_like(arr)\n",
        "\n",
        "    threads_per_block = TPB\n",
        "    blocks = (n + threads_per_block - 1) // threads_per_block\n",
        "\n",
        "    d_arr = cuda.to_device(arr)\n",
        "    d_out = cuda.to_device(out)\n",
        "\n",
        "    d_hist = cuda.device_array((blocks, 11), dtype=np.int32)\n",
        "    offsets_host = np.zeros((11, blocks), dtype=np.int32)\n",
        "\n",
        "    max_val = arr.max()\n",
        "    exp = 1\n",
        "\n",
        "    while max_val // exp > 0:\n",
        "        d_hist.copy_to_device(np.zeros((blocks, 11), dtype=np.int32)) # Reset\n",
        "        count_kernel[blocks, threads_per_block](d_arr, d_hist, exp, n)\n",
        "\n",
        "        hist = d_hist.copy_to_host()\n",
        "        total_counts = np.sum(hist, axis=0)\n",
        "\n",
        "        digit_starts = np.zeros(11, dtype=np.int32)\n",
        "        current_sum = 0\n",
        "        for d in range(10):\n",
        "            digit_starts[d] = current_sum\n",
        "            current_sum += total_counts[d]\n",
        "\n",
        "        for d in range(10):\n",
        "            col_cumsum = 0\n",
        "            start = digit_starts[d]\n",
        "            for b in range(blocks):\n",
        "                offsets_host[d, b] = start + col_cumsum\n",
        "                col_cumsum += hist[b, d]\n",
        "\n",
        "        d_offsets = cuda.to_device(offsets_host)\n",
        "\n",
        "        scatter_kernel[blocks, threads_per_block](d_arr, d_out, d_offsets, exp, n)\n",
        "\n",
        "        d_arr, d_out = d_out, d_arr\n",
        "        exp *= 10\n",
        "\n",
        "    return d_arr.copy_to_host()\n",
        "\n"
      ],
      "metadata": {
        "id": "VLzQ-MaQNvwj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "from pathlib import Path\n",
        "\n",
        "def get_paths_to_data(path):\n",
        "  paths = []\n",
        "  for file in Path(path).glob('**/*.txt'):\n",
        "    paths.append(file)\n",
        "  return paths\n",
        "\n",
        "paths = get_paths_to_data(\".\")\n",
        "for path in paths:\n",
        "    times = []\n",
        "    for i in range(10):\n",
        "      text = Path(path).read_text()\n",
        "      arr = np.array([int(x) for x in text.split()], dtype=np.int32)\n",
        "      start_time = time.time()\n",
        "      sorted_arr = radix_sort_cuda_stable(arr)\n",
        "      end_time= time.time()\n",
        "      elapsed_time = end_time - start_time\n",
        "      times.append(elapsed_time)\n",
        "\n",
        "    avg_time = np.mean(times)\n",
        "    print(f\"{path},{str(path).split('.')[0].split('_')[-1]},{avg_time}\")\n",
        "    with open(\"results.csv\", \"a\") as f:\n",
        "      f.write(f\"{path},{str(path).split(\".\")[0].split(\"_\")[-1]},{avg_time}\\n\")\n",
        "\n"
      ],
      "metadata": {
        "id": "2J9OvVEhRieV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "62796da2-60e4-4525-c20b-14c152c1259d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "almost_sorted_data_100000.txt,100000,0.33749434947967527\n",
            "random_data_1000.txt,1000,0.004011631011962891\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/numba_cuda/numba/cuda/dispatcher.py:697: NumbaPerformanceWarning: Grid size 32 will likely result in GPU under-utilization due to low occupancy.\n",
            "  warn(NumbaPerformanceWarning(msg))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "almost_sorted_data_1000000.txt,1000000,0.7879453897476196\n",
            "data_with_duplicates_100000.txt,100000,0.02597332000732422\n",
            "almost_sorted_data.txt,data,0.008073830604553222\n",
            "random_data_100000.txt,100000,0.08139693737030029\n",
            "data_with_duplicates_1000.txt,1000,0.002241992950439453\n",
            "almost_sorted_data_1000.txt,1000,0.003189873695373535\n",
            "data_with_duplicates.txt,duplicates,0.0026960372924804688\n",
            "random_data.txt,data,0.009513568878173829\n",
            "example_data.txt,data,0.001293492317199707\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/numba_cuda/numba/cuda/dispatcher.py:697: NumbaPerformanceWarning: Grid size 1 will likely result in GPU under-utilization due to low occupancy.\n",
            "  warn(NumbaPerformanceWarning(msg))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "random_data_1000000.txt,1000000,0.9049330472946167\n",
            "data_with_duplicates_1000000.txt,1000000,0.30639622211456297\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"results.csv\", \"a\") as f:\n",
        "  f.write(\"--------------------------------------,32,---\\n\")"
      ],
      "metadata": {
        "id": "chhNbZVrD0Nn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def counting_sort_for_radix(arr, exp):\n",
        "    n = len(arr)\n",
        "    output = [0] * n\n",
        "    count = [0] * 10\n",
        "\n",
        "    for i in range(n):\n",
        "        index = (arr[i] // exp) % 10\n",
        "        count[index] += 1\n",
        "\n",
        "    for i in range(1, 10):\n",
        "        count[i] += count[i - 1]\n",
        "\n",
        "    for i in range(n - 1, -1, -1):\n",
        "        index = (arr[i] // exp) % 10\n",
        "        output[count[index] - 1] = arr[i]\n",
        "        count[index] -= 1\n",
        "\n",
        "    for i in range(n):\n",
        "        arr[i] = output[i]\n",
        "\n",
        "\n",
        "def radix_sort(arr):\n",
        "    if not arr.any():\n",
        "        return arr\n",
        "\n",
        "    max_val = max(arr)\n",
        "    exp = 1\n",
        "    while max_val // exp > 0:\n",
        "        counting_sort_for_radix(arr, exp)\n",
        "        exp *= 10\n",
        "    return arr\n"
      ],
      "metadata": {
        "id": "oNi7VMlqPjYq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "paths = get_paths_to_data(\".\")\n",
        "for path in paths:\n",
        "    times = []\n",
        "    for i in range(10):\n",
        "      text = Path(path).read_text()\n",
        "      arr = np.array([int(x) for x in text.split()], dtype=np.int32)\n",
        "\n",
        "      start_time = time.time()\n",
        "      sorted_arr = radix_sort(arr)\n",
        "      end_time= time.time()\n",
        "\n",
        "      elapsed_time = end_time - start_time\n",
        "      times.append(elapsed_time)\n",
        "\n",
        "    avg_time = np.mean(times)\n",
        "    print(f\"{path},{str(path).split('.')[0].split('_')[-1]},{avg_time}\")\n",
        "    with open(\"results_without_cuda.csv\", \"a\") as f:\n",
        "      f.write(f\"{path},{str(path).split(\".\")[0].split(\"_\")[-1]},{avg_time}\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HsqJS9EBSErw",
        "outputId": "9454c4a2-afe6-4ed3-da46-8fe5a5d17c40"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "almost_sorted_data_100000.txt,100000,0.5678539037704468\n",
            "random_data_1000.txt,1000,0.003662872314453125\n",
            "almost_sorted_data_1000000.txt,1000000,6.172169518470764\n",
            "data_with_duplicates_100000.txt,100000,0.21702773571014405\n",
            "almost_sorted_data.txt,data,0.07053890228271484\n",
            "random_data_100000.txt,100000,0.5884534835815429\n",
            "data_with_duplicates_1000.txt,1000,0.00177457332611084\n",
            "almost_sorted_data_1000.txt,1000,0.0027520179748535155\n",
            "data_with_duplicates.txt,duplicates,0.010458278656005859\n",
            "random_data.txt,data,0.03611955642700195\n",
            "example_data.txt,data,4.2390823364257815e-05\n",
            "random_data_1000000.txt,1000000,7.58461365699768\n",
            "data_with_duplicates_1000000.txt,1000000,2.254510688781738\n"
          ]
        }
      ]
    }
  ]
}